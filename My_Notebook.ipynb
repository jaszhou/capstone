{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(spark.sparkContext, '7733d04b-b741-43f2-8ec9-1012cbdf49ff', 'p-9eb65afff388e68370273006319c8b9e2368776a')\npc = project.project_context\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 18
        }, 
        {
            "source": "1+1", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "2"
                    }, 
                    "execution_count": 17, 
                    "metadata": {}
                }
            ], 
            "execution_count": 17
        }, 
        {
            "source": "!pwd", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190328005534-0000\nKERNEL_ID = f776e898-4008-4f21-9e27-c4d351c0ca90\n/home/spark/shared\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "<h1> lab </h1>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!ls -l", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "total 12\r\ndrwxr-xr-x 2 spark spark 4096 Mar 28 00:55 logs\r\ndrwxr-xr-x 2 spark spark 4096 Mar 28 00:55 spark-events\r\ndrwxr-xr-x 6 spark spark 4096 Mar 28 00:55 user-libs\r\n"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "!cd user-libs", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 15
        }, 
        {
            "source": "!cd ~", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 5
        }, 
        {
            "source": "!ls -l", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "total 12\r\ndrwxr-xr-x 2 spark spark 4096 Mar 28 00:55 logs\r\ndrwxr-xr-x 2 spark spark 4096 Mar 28 00:55 spark-events\r\ndrwxr-xr-x 6 spark spark 4096 Mar 28 00:55 user-libs\r\n"
                }
            ], 
            "execution_count": 16
        }, 
        {
            "source": "!pwd", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/home/spark/shared\r\n"
                }
            ], 
            "execution_count": 6
        }, 
        {
            "source": "!cd user-libs", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 8
        }, 
        {
            "source": "\nimport sys\nimport types\nimport pip\n\n#if not('ibm-cos-sdk' in [package.project_name for package in pip.get_installed_distributions()]):\n #   !pip install ibm-cos-sdk==2.0.0 -q\n\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_1b33b2bf509b4d1a9c5fbf6ff8374058 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='sbxZ5J_l9Ml8K9zL0KxqAi6QPjn-u_WA-fCsjwxKATR0',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_1b33b2bf509b4d1a9c5fbf6ff8374058.get_object(Bucket='myproject-donotdelete-pr-fcpxq2mngiabpy',Key='bank.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age;\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30;\"unemployed\";\"married\";\"primary\";\"no\";1787;...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33;\"services\";\"married\";\"secondary\";\"no\";4789;...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35;\"management\";\"single\";\"tertiary\";\"no\";1350;...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30;\"management\";\"married\";\"tertiary\";\"no\";1476...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;...</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  age;\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n0  30;\"unemployed\";\"married\";\"primary\";\"no\";1787;...                                                                                                  \n1  33;\"services\";\"married\";\"secondary\";\"no\";4789;...                                                                                                  \n2  35;\"management\";\"single\";\"tertiary\";\"no\";1350;...                                                                                                  \n3  30;\"management\";\"married\";\"tertiary\";\"no\";1476...                                                                                                  \n4  59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;...                                                                                                  "
                    }, 
                    "execution_count": 19, 
                    "metadata": {}
                }
            ], 
            "execution_count": 19
        }, 
        {
            "source": "#pd.save_csv(data=df_data_1.to_csv(index=False),file_name='iris1.csv',overwrite=True)\n\ndf_data_1.to_csv('output.csv', sep='\\t', encoding='utf-8')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 20
        }, 
        {
            "source": "!ls -l", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "total 12\r\ndrwxr-xr-x 2 spark spark 4096 Mar 28 00:55 logs\r\ndrwxr-xr-x 2 spark spark 4096 Mar 28 00:55 spark-events\r\ndrwxr-xr-x 6 spark spark 4096 Mar 28 00:55 user-libs\r\n"
                }
            ], 
            "execution_count": 25
        }, 
        {
            "source": "!pwd", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/home/spark/shared\r\n"
                }
            ], 
            "execution_count": 22
        }, 
        {
            "source": "project.save_data(data=df_data_1.to_csv(index=False),file_name='iris1.csv',overwrite=True)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "{'asset_id': 'e2846bdd-5d0a-4107-9b61-074f407dcfd5',\n 'bucket_name': 'myproject-donotdelete-pr-fcpxq2mngiabpy',\n 'file_name': 'iris1.csv',\n 'message': 'File iris1.csv has been written successfully to the associated OS'}"
                    }, 
                    "execution_count": 23, 
                    "metadata": {}
                }
            ], 
            "execution_count": 23
        }, 
        {
            "source": "!rm output.csv", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 24
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark", 
            "name": "python3", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}